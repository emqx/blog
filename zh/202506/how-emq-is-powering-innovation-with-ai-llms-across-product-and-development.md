大语言模型（LLM）的快速发展正从根本上重塑科技公司的运营模式——从增强产品能力到优化内部开发流程。EMQ 映云科技不仅是这场变革的见证者，更是积极的引领者。公司在人工智能的融合应用方面有着深远的战略布局，远不止于为产品添加「智能功能」这般简单。映云科技坚信应利用 AI 赋能开发者、加速创新周期，并最终为用户和客户提供更卓越的体验。

本文将初步探讨映云科技更广泛的 AI 战略，并深入介绍 EMQX 团队利用 LLM 提升日常开发效率的几个具体的技术实践。

## 更广泛的 AI 战略布局

映云科技对 AI 的投入是全方位的，涵盖其业务的各个方面，以增强产品能力并优化运营效率。具体包括：

- **社区支持：** 在 EMQX Discord 频道部署 AI 聊天机器人，提供实时社区协助。
- **产品增强：**
  - **EMQX 规则引擎：**将 `ai_completion` 调用集成到 EMQX 规则引擎中，实现智能消息处理。
  - [**MQTTX Copilot**](https://www.emqx.com/en/blog/mqttx-1-9-7-release-notes)**：**将 LLM 与 MQTT 操作相结合，简化并支持自动化开发。
  - **NeuronEX IIoT 数据分析：**利用 LLM 和 RAG 进行自然语言数据探索和自动化故障排除。
- **内部优化：**
  - 利用 LLM 自动将 Jira 和 Slack 中的知识聚合到 RAG 数据库中，提高故障排除效率。
  - 开发 API 将错误日志输入 LLM 以支持客户自助诊断。

这些一系列举措奠定了映云科技「AI 优先」的企业定位，提升运营效率、推动产品创新并优化用户体验。

## 利用 LLM 推动 EMQX 开发

除了公司层面的广泛举措外，EMQX 核心开发团队还特别利用 LLM 来简化内部流程。这些努力尚未大规模公开，但却代表着开发人员生产力和产品质量的显著提升。

### 自动化 i18n 翻译

对于像 EMQX 这样快速发展的技术产品来说，国际化 (i18n) 翻译工作本身就存在诸多困难，而且过程通常繁琐耗时。传统方式下，这会占用开发人员核心代码编写和功能开发的时间。此外，翻译不一致或延迟的风险也可能对全球用户体验产生负面影响。

EMQX 通过使用 LLM 实现翻译流程的高度自动化，有效应对上述挑战。这带来了角色定位的根本性转变：开发人员现在可以专注于用英语编写代码和文档，作为源语言和事实依据，而 LLM 则负责初始翻译。这使得文档撰写人员能够集中精力审阅和优化 AI 生成的译文，从而显著提高整体效率和准确性。

AI 技术的应用对开发人员工作效率的提升，使工程师能够专注于创新和复杂问题的解决。这种对内部流程的持续优化，直接转化为更快的产品开发周期和更高质量的代码，最终惠及更多终端用户。

GitHub 仓库 `emqx-i18n` 是这些翻译的中心枢纽。翻译文件采用 HOCON 格式（JSON 的超集），后缀 `.hocon` 用于特定的构建流程。

自动翻译的工作流程是系统化的：

1. 首先从主 EMQX 存储库同步英文文档。
2. 然后对当前文档的英文版、中文版和基准版本进行三方比较，以识别变更。此过程会标记已更新的文档，并在新旧英文版本中添加 `"NEED_TRANSLATION"` 注释，同时标记中文文件中缺失待译的内容。
3. 将识别出的差异内容与包含对 LLM 指令的提示文件 (`prompt.hocon`) 进行整合，并将整合后的信息输入 LLM 进行翻译。
4. 随后将 LLM 生成的译文合并到主中文文档文件中，进行格式化并提交。
5. 最后，由人工翻译人员审阅新生成的内容以修正任何错误，最终定稿。

这种系统化的方法能够确保翻译始终与产品变化保持同步，最大限度地减少人工成本并保持语言一致性。自动化 i18n 更广泛的意义在于能够更轻松、更一致地扩展翻译规模。这使得 EMQX 能够凭借高质量、本地化的文档和产品界面触达更广泛的全球受众，有效打破语言障碍。

因此，AI 驱动的 i18n 不仅实现了效率提升，更是一项加速非英语地区市场渗透和用户使用的战略举措，使 EMQX 成为真正意义上的全球化产品。

### **大模型生成产品配置参数**

EMQX 作为一款功能强大且灵活的 [MQTT Broker](https://www.emqx.com/zh/blog/the-ultimate-guide-to-mqtt-broker-comparison)，提供了丰富的配置选项。这种灵活性固然有益，但也带来了巨大的挑战：超过 30 种数据集成和众多参数（例如 TLS 设置、批处理配置以及数据接收器和数据源的各种身份认证方法等），对于人工文档团队来说，为每种可能的组合编写全面且准确的配置示例是一项极其艰巨的任务，甚至是不可能完成的。这种固有的复杂性，对于试图根据自身特定需求设置 EMQX 的用户来说，可能是一个巨大的障碍，经常导致错误并增加了支持请求。

为了解决这个问题，EMQX 利用 LLM 及其自动生成的配置模式，动态生成高度准确且与上下文相关的配置示例。LLM 可以智能地利用配置字段类型、描述、默认值，甚至用户提供的上下文，做出非常合理的推测，生成几乎可以直接复制粘贴到其部署中的、有意义的示例，这直接解决了用户的一个主要痛点。通过 AI 使配置变得更简单直观，EMQX 显著降低了新用户的入门门槛，加速了产品的普及。

用户可以浏览 EMQX 配置模式，并点击特定的配置路径来生成特定结构的示例。然后，他们可以交互式地深入配置树，构建符合其具体需求的示例。这种智能生成功能的关键在于 EMQX 基于 HOCON（JSON 的超集）的定义明确的配置模式，该模式提供了结构化数据（包括字段类型、描述和默认值）作为 LLM 的基础知识。虽然用于指导 LLM 生成这些示例的特定提示无法直接访问，但其存在确保了输出符合 EMQX 的配置语法和最佳实践。  

这种由 LLM 支持的配置示例生成具有以下优势：

- **增强用户能力：**用户可以轻松构建完全符合其特定要求的示例，减少猜测和反复试验。
- **减少人为错误：** LLM 生成的示例本质上不太容易出现人为错误，从而实现更顺畅、更可靠的部署。
- **加速价值实现：**用户可以快速配置和运行他们的 EMQX 部署，缩短项目周期。
- **减轻支持负担：**更少的配置相关问题直接减轻了客户支持团队的压力。

这种方法显著提升了 EMQX 的整体开发者体验，使产品更具吸引力，并缩短了从安装到成功部署的时间。此外，人工记录所有配置组合根本不可行。LLM 驱动的生成能力无限扩展以适应产品的复杂性，确保映云科技能够在不相应增加人力投入的情况下，维护全面、最新且个性化的文档。这代表着复杂产品知识传播方式的根本性转变，将文档从静态的产物转变为动态的交互式工具，促进产品专家向最终用户更好地进行知识传递。

### 使用 OpenHands 自动解决文档问题

维护大量技术文档（例如 [EMQX 官方文档网站）](https://docs.emqx.com/en/emqx/latest/)的准确性和时效性是一项持续的挑战。为了解决这一问题，映云科技开创性地使用自主 AI 代理 [OpenHands](https://github.com/All-Hands-AI/OpenHands) 来自动解决` emqx/emqx-docs` 存储库中的问题。当发现文档错误或需要澄清的问题，并判定适合 AI 干预时，开发者只需在对应的 GitHub issue 上添加 `fix-with-ai` 标签。此操作将触发自动化工作流程，授权 OpenHands 了解问题所在，浏览文档存储库，进行必要的修改，并提交包含修复内容的 Pull Request。

这种创新方法不仅加速了文档问题的解决，确保用户能够获得最可靠的信息，还进一步解放了产研团队，使他们能够专注于开发核心产品功能并应对更复杂的文档挑战。这强化了映云科技利用 AI 实现端到端开发效率的承诺，将 AI 驱动的增强能力从代码生成和翻译直接延伸到面向用户的重要文档的维护与改进。

## 映云科技的 AI 未来

EMQ + AI 正在改变企业运营的方方面面。

映云科技的战略决策是将 AI 深度整合到整个组织，而非将其分散到各个项目中，这巩固了映云科技作为一家创新型、AI 驱动型公司的品牌形象。这种整体方法确保 AI 不仅仅是一项功能，更是提升效率、产品质量和卓越用户体验的根本推动力。通过分享内部 AI 战略并邀请社区参与，映云科技正在潜移默化地构建一个协作生态系统。这种透明度可以营造更活跃的社区氛围，鼓励外部贡献并建立反馈循环，从而进一步加速 AI 应用和创新。

映云科技正在积极构建 AI 赋能开发者和用户的未来，让物联网解决方案更加智能、高效，人人可用。我们诚邀开发者和物联网爱好者探索 EMQX 及其不断扩展的 AI 功能套件。欢迎加入 EMQX Discord 社区，探索 GitHub 代码库，并分享您对 AI 如何塑造未来开发的看法。



<section class="promotion">
    <div>
        咨询 EMQ 技术专家
    </div>
    <a href="https://www.emqx.com/zh/contact?product=solutions" class="button is-gradient">联系我们 →</a>
</section>
